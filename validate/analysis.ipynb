{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b99692-269a-4e5e-a383-8b5181e8ebda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from itertools import chain, count, islice, repeat\n",
    "from pathlib import Path\n",
    "from typing import Iterator\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn.objects as so\n",
    "from itables import init_notebook_mode\n",
    "\n",
    "init_notebook_mode(all_interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9851875-4b8d-4bb7-832a-f900893290c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type Event = tuple[str, str, str, str | None, str | None, str | None, str | None]\n",
    "\n",
    "\n",
    "def parse_entry(line: str, lines_iter: Iterator[str]) -> Iterator[Event]:\n",
    "    # example with 3 log entries\n",
    "    #\n",
    "    # 2025-10-08T17:36:08.987-03:00 debug id 207 value 0\n",
    "    # w: 0 39 36 74 146 301 597 1029 0 0 0 0 0 0 0 0 0\n",
    "    # s: 66777 65256 2078 918 13016 30650 33489 0 0 0 0 0 0 0 0 0 0\n",
    "    # 2025-10-08T17:36:09.237-03:00 detected level 2\n",
    "    # 2025-10-08T17:36:09.237-03:00 debug id 208 value 0\n",
    "    # w: 0 39 36 74 149 301 597 1029 0 0 0 0 0 0 0 0 0\n",
    "    # s: 66777 66777 2087 919 13016 30650 33489 0 0 0 0 0 0 0 0 0 0\n",
    "    words = line.split()\n",
    "\n",
    "    timestamp, entry_type = words[0], words[1]\n",
    "    match entry_type:\n",
    "        case \"detected\":\n",
    "            assert words[2] == \"level\"\n",
    "            level = words[3]\n",
    "\n",
    "            yield (\n",
    "                timestamp,\n",
    "                entry_type,\n",
    "                level,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "            )\n",
    "\n",
    "        case \"debug\":\n",
    "            assert words[2] == \"id\"\n",
    "            idx = words[3]\n",
    "\n",
    "            assert words[4] == \"value\"\n",
    "            sample = words[5]\n",
    "\n",
    "            w_header, *ws = next(lines_iter).split()\n",
    "            s_header, *ss = next(lines_iter).split()\n",
    "\n",
    "            assert w_header == \"w:\"\n",
    "            assert s_header == \"s:\"\n",
    "            assert len(ws) == len(ss)\n",
    "\n",
    "            # basically explode w and s columns\n",
    "            yield from zip(\n",
    "                repeat(timestamp),\n",
    "                repeat(entry_type),\n",
    "                map(str, count()),  # 0, 1, 2...\n",
    "                repeat(idx),\n",
    "                repeat(sample),\n",
    "                ws,\n",
    "                ss,\n",
    "            )\n",
    "\n",
    "        case _:\n",
    "            raise Exception(\"non-conforming log or bug in parser\")\n",
    "\n",
    "\n",
    "def parse_file(file_name: Path):\n",
    "    interval_ns = re.search(r\"-t(\\d+)\", str(file_name)).group(1)\n",
    "\n",
    "    lines_iter = iter(open(file_name))\n",
    "    while (line := next(lines_iter, None)) is not None:\n",
    "        yield from [\n",
    "            (str(file_name), interval_ns, *entry)\n",
    "            for entry in parse_entry(line, lines_iter)\n",
    "        ]\n",
    "\n",
    "\n",
    "log_files = [\n",
    "    f\n",
    "    for f in Path(\"results\").iterdir()\n",
    "    if (f.is_file() and not f.name.endswith(\".err\"))\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    chain.from_iterable([parse_file(log_file) for log_file in log_files]),\n",
    "    columns=[\n",
    "        \"capture\",\n",
    "        \"interval_ns\",\n",
    "        \"timestamp\",\n",
    "        \"type\",\n",
    "        \"decomposition_level\",\n",
    "        \"index\",\n",
    "        \"sample\",\n",
    "        \"w\",\n",
    "        \"s\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "dtype_mapping = {\n",
    "    \"capture\": \"category\",\n",
    "    \"interval_ns\": \"uint64\",\n",
    "    \"type\": \"category\",\n",
    "    \"decomposition_level\": \"uint16\",\n",
    "    # Use nullable unsigned integers for columns that may contain missing values\n",
    "    \"index\": \"UInt64\",\n",
    "    \"sample\": \"UInt64\",\n",
    "    \"w\": \"UInt64\",\n",
    "    \"s\": \"UInt64\",\n",
    "}\n",
    "\n",
    "# Apply the type conversions\n",
    "df = df.astype(dtype_mapping)\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"ISO8601\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a922c9d-3b8c-4fbd-9f06-2be4b2c9e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_debug = df[\"type\"] == \"debug\"\n",
    "df[df_debug].drop_duplicates(subset=[\"capture\", \"index\", \"sample\"]).groupby(\n",
    "    \"capture\", observed=True\n",
    ")[\"sample\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2cd75-3242-4a88-b481-60d3aade0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 3\n",
    "beta = 2\n",
    "\n",
    "df = df.sort_values(by=[\"capture\", \"index\", \"decomposition_level\"])\n",
    "\n",
    "prev_s = df.groupby([\"capture\", \"index\"], observed=True)[\"s\"].shift(1)\n",
    "\n",
    "df[\"drop\"] = (beta * prev_s) > (2 * alpha * df[\"s\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93371d7c-6188-4f75-9a4c-8b9efed1e2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "captures = df[\"capture\"].unique()\n",
    "timestamps = {}\n",
    "for capture in captures:\n",
    "    timestamps[capture] = df[df[\"capture\"] == capture][\"timestamp\"]\n",
    "\n",
    "initial_capture = captures[0]\n",
    "initial_timestamps = df[df[\"capture\"] == initial_capture][\"timestamp\"]\n",
    "\n",
    "capture_dropdown = widgets.Dropdown(options=captures, description=\"Capture:\")\n",
    "\n",
    "timestamp_slider = widgets.SelectionSlider(\n",
    "    options=initial_timestamps, description=\"Timestamp\", layout={\"width\": \"800px\"}\n",
    ")\n",
    "\n",
    "\n",
    "def update_timestamp_options(change):\n",
    "    selected_capture = change[\"new\"]\n",
    "    timestamp_slider.options = timestamps[selected_capture]\n",
    "\n",
    "\n",
    "capture_dropdown.observe(update_timestamp_options, names=\"value\")\n",
    "\n",
    "\n",
    "def update_plot(capture, timestamp):\n",
    "    filtered_data = df[(df[\"capture\"] == capture) & (df[\"timestamp\"] == timestamp)]\n",
    "    p = (\n",
    "        so.Plot(filtered_data, \"decomposition_level\", \"s\")\n",
    "        .add(so.Line())\n",
    "        .add(so.Dot(), color=\"drop\")\n",
    "        .scale(color=[\"red\", \"blue\"])\n",
    "    )\n",
    "    display(p)\n",
    "\n",
    "\n",
    "widgets.interactive(update_plot, capture=capture_dropdown, timestamp=timestamp_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bfce2d-ee5f-429b-9dc3-994a33480394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "so.Plot(\n",
    "    df[df[\"index\"] == df.groupby(\"capture\", observed=True)[\"index\"].transform(\"max\")],\n",
    "    \"decomposition_level\",\n",
    "    \"s\",\n",
    "    color=\"capture\",\n",
    ").add(so.Line())\n",
    "\n",
    "\n",
    "for capture in df[\"capture\"].unique():\n",
    "    filtered = df[\n",
    "        (df[\"capture\"] == capture)\n",
    "        & (\n",
    "            df[\"index\"]\n",
    "            == df.groupby(\"capture\", observed=True)[\"index\"].transform(\"max\")\n",
    "        )\n",
    "    ]\n",
    "    p = (\n",
    "        so.Plot(filtered, \"decomposition_level\", \"s\")\n",
    "        .add(so.Line())\n",
    "        .add(so.Dot(), color=\"drop\")\n",
    "        .scale(color=[\"red\", \"blue\"])\n",
    "        .label(title=capture)\n",
    "    )\n",
    "    display(p)\n",
    "# p.save(f\"./plots/{capture}.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c73f0f-02fb-4081-83da-c46e519c4614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "\n",
    "def level_to_period(interval):\n",
    "    return lambda x: np.exp2(x) * interval\n",
    "\n",
    "\n",
    "def period_to_level(interval):\n",
    "    return lambda x: ma.log2(x / interval)\n",
    "\n",
    "\n",
    "def ns_to_s(ns, pos):\n",
    "    return ns / 1_000_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47717c48-e308-4750-84be-5506f9538e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use([\"default\", \"science\", \"grid\", \"ieee\"])\n",
    "\n",
    "max_index_series = df.groupby(\"capture\", observed=True)[\"index\"].transform(\"max\")\n",
    "\n",
    "captures = df[\"capture\"].unique()\n",
    "\n",
    "selected_captures = [\n",
    "    # 'cobalt-strike-filtered-trimmed_-t250000000',\n",
    "    # 'heartbleed-full_-t250000000',\n",
    "    \"trickbot-a-filtered-trimmed-further_-t60000000\",\n",
    "    \"trickbot-b-filtered-trimmed-further_-t60000000\",\n",
    "]\n",
    "captures = filter(lambda x: any(s in x for s in selected_captures), captures)\n",
    "\n",
    "for capture in captures:\n",
    "    filtered = df[\n",
    "        (df[\"capture\"] == capture)\n",
    "        & (df[\"index\"] == max_index_series)\n",
    "        & (df[\"decomposition_level\"] <= 13)\n",
    "    ]\n",
    "    interval = filtered[\"interval_ns\"].iloc[0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.set_yscale(\"symlog\")\n",
    "\n",
    "    ax.plot(filtered[\"decomposition_level\"], filtered[\"s\"])\n",
    "    # colors = filtered[\"drop\"].fillna(False).map({False: \"blue\", True: \"red\"}).tolist()\n",
    "    # ax.scatter(filtered[\"decomposition_level\"], filtered[\"s\"], c=colors)\n",
    "    ax.xaxis.minorticks_off()\n",
    "\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=1))\n",
    "    # ax.set_title(capture)\n",
    "    ax.set_xlabel(\"Decomposition Level\")\n",
    "    ax.set_ylabel(\"S value\")\n",
    "\n",
    "    # Secondary axis at the top showing period in seconds for each decomposition level\n",
    "    secax = ax.secondary_xaxis(\n",
    "        \"top\", functions=(level_to_period(interval), period_to_level(interval))\n",
    "    )\n",
    "    secax.tick_params(\"x\", rotation=90)\n",
    "    secax.set_xlabel(\"Period (s)\")\n",
    "    secax.xaxis.minorticks_off()\n",
    "    secax.set_xticks(level_to_period(interval)(ax.get_xticks()), minor=False)\n",
    "    secax.xaxis.set_major_formatter(ns_to_s)\n",
    "\n",
    "    # plt.show()\n",
    "    fig.savefig(f\"{capture.removeprefix('results/')}.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
